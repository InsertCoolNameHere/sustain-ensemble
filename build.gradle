plugins {
    // Provide convenience executables for trying out the examples.
    id 'application'
    // ASSUMES GRADLE 2.12 OR HIGHER. Use plugin version 0.7.5 with earlier gradle versions
    id 'com.google.protobuf' version '0.8.8'
    // For generating fat/uber JARs
    id 'com.github.johnrengelman.shadow' version '6.1.0'
    // Generate IntelliJ IDEA's .idea & .iml project files
    id 'idea'
    // For Scala source code in the project
    id 'scala'
    // For Java source code in the project
    id 'java'
}

group 'org.sustain.census'
version '1.0-SNAPSHOT'

repositories {
    mavenLocal()
    mavenCentral()
}

// We need to use JDK 1.11 for cross-compatibility between Scala and Java
sourceCompatibility = 1.11

// updating the version in our release process.
def grpcVersion = '1.28.1' // CURRENT_GRPC_VERSION
def nettyTcNativeVersion = '2.0.30.Final'
def protocVersion = '3.11.0'

dependencies {

    // --- Java source dependencies ---
    implementation "io.grpc:grpc-netty:${grpcVersion}"
    implementation "io.grpc:grpc-protobuf:${grpcVersion}"
    implementation "io.grpc:grpc-stub:${grpcVersion}"
    implementation group: 'org.apache.logging.log4j', name: 'log4j-api', version: '2.8'
    implementation group: 'org.apache.logging.log4j', name: 'log4j-core', version: '2.8'
    implementation 'org.json:json:20171018'
    implementation group: 'org.mongodb', name: 'mongo-java-driver', version: '3.12.5'
    implementation group: 'com.google.code.gson', name: 'gson', version: '2.7'
    compileOnly 'org.apache.tomcat:annotations-api:6.0.53'
    runtimeOnly "io.netty:netty-tcnative-boringssl-static:${nettyTcNativeVersion}"

    // --- Testing dependencies ---
    testImplementation "io.grpc:grpc-testing:${grpcVersion}"
    testImplementation "org.mockito:mockito-core:1.9.5"
    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.3.1'
    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.3.1'

    // --- Scala/Spark source dependencies ---
    implementation 'org.scala-lang:scala-library:2.12.12'
    implementation 'org.scala-lang.modules:scala-xml_2.12:1.2.0'
    implementation 'org.apache.spark:spark-core_2.12:3.0.0'
    implementation 'org.apache.spark:spark-sql_2.12:3.0.0'
    implementation 'org.apache.spark:spark-mllib_2.12:3.0.0'
    implementation 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.0'

}

// Inform IDEs like IntelliJ IDEA, Eclipse or NetBeans about the generated code.
// Defines where the source code is for respective compilation targets.
sourceSets {

    // Separate Scala source directories from Java source directories.
    main {
        scala {
            srcDirs = ['src/main/scala']
            outputDir = file("$buildDir/classes/scala/main")
        }
        java {
            srcDirs = ['src/main/java', 'build/generated/source/proto/main/grpc', 'build/generated/source/proto/main/java']
            outputDir = file("$buildDir/classes/java/main")
        }
    }
    test {
        java {
            srcDirs = ['src/test/java']
        }
    }
}

test {
    useJUnitPlatform()
}

// Output to build/libs/shadow.jar
shadowJar {
    zip64 true
    archiveBaseName.set('shadow')
    archiveClassifier.set('')
    archiveVersion.set('')
}

shadow {
    // Define entrypoint for the Scala fat JAR
    mainClassName = 'org.sustain.HelloWorld'
}

protobuf {
    protoc { artifact = "com.google.protobuf:protoc:${protocVersion}" }
    plugins {
        grpc { artifact = "io.grpc:protoc-gen-grpc-java:${grpcVersion}" }
    }
    generateProtoTasks {
        all()*.plugins { grpc {} }
    }
}

startScripts.enabled = false

task sustainServer(type: CreateStartScripts) {
    mainClassName = 'org.sustain.server.SustainServer'
    applicationName = 'sustain-server'
    outputDir = new File(project.buildDir, 'tmp')
    classpath = startScripts.classpath
}

task censusClient(type: CreateStartScripts) {
    mainClassName = 'org.sustain.client.CensusClient'
    applicationName = 'census-client'
    outputDir = new File(project.buildDir, 'tmp')
    classpath = startScripts.classpath
}

task sparkJob(type: CreateStartScripts) {
    mainClassName = 'org.sustain.modeling.SparkJob'
    applicationName = 'spark-job'
    outputDir = new File(project.buildDir, 'tmp')
    classpath = startScripts.classpath
}

task spatialClient(type: CreateStartScripts) {
    mainClassName = 'org.sustain.client.SpatialClient'
    applicationName = 'spatial-client'
    outputDir = new File(project.buildDir, 'tmp')
    classpath = startScripts.classpath
}

applicationDistribution.into('bin') {
    from(sustainServer)
    from(censusClient)
    from(sparkJob)
    from(spatialClient)
    fileMode = 0755
}
